{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import Imputer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import Imputer, LabelEncoder\n",
    "from sklearn.ensemble import BaggingClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, make_scorer\n",
    "from sklearn.preprocessing import Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X56</th>\n",
       "      <th>X57</th>\n",
       "      <th>X58</th>\n",
       "      <th>X59</th>\n",
       "      <th>X60</th>\n",
       "      <th>X61</th>\n",
       "      <th>X62</th>\n",
       "      <th>X63</th>\n",
       "      <th>X64</th>\n",
       "      <th>X65</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.200550</td>\n",
       "      <td>0.37951</td>\n",
       "      <td>0.39641</td>\n",
       "      <td>2.0472</td>\n",
       "      <td>32.3510</td>\n",
       "      <td>0.38825</td>\n",
       "      <td>0.249760</td>\n",
       "      <td>1.33050</td>\n",
       "      <td>1.1389</td>\n",
       "      <td>0.50494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121960</td>\n",
       "      <td>0.39718</td>\n",
       "      <td>0.87804</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>8.4160</td>\n",
       "      <td>5.1372</td>\n",
       "      <td>82.658</td>\n",
       "      <td>4.4158</td>\n",
       "      <td>7.4277</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.209120</td>\n",
       "      <td>0.49988</td>\n",
       "      <td>0.47225</td>\n",
       "      <td>1.9447</td>\n",
       "      <td>14.7860</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.258340</td>\n",
       "      <td>0.99601</td>\n",
       "      <td>1.6996</td>\n",
       "      <td>0.49788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.121300</td>\n",
       "      <td>0.42002</td>\n",
       "      <td>0.85300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.1486</td>\n",
       "      <td>3.2732</td>\n",
       "      <td>107.350</td>\n",
       "      <td>3.4000</td>\n",
       "      <td>60.9870</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.248660</td>\n",
       "      <td>0.69592</td>\n",
       "      <td>0.26713</td>\n",
       "      <td>1.5548</td>\n",
       "      <td>-1.1523</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.309060</td>\n",
       "      <td>0.43695</td>\n",
       "      <td>1.3090</td>\n",
       "      <td>0.30408</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241140</td>\n",
       "      <td>0.81774</td>\n",
       "      <td>0.76599</td>\n",
       "      <td>0.694840</td>\n",
       "      <td>4.9909</td>\n",
       "      <td>3.9510</td>\n",
       "      <td>134.270</td>\n",
       "      <td>2.7185</td>\n",
       "      <td>5.2078</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.081483</td>\n",
       "      <td>0.30734</td>\n",
       "      <td>0.45879</td>\n",
       "      <td>2.4928</td>\n",
       "      <td>51.9520</td>\n",
       "      <td>0.14988</td>\n",
       "      <td>0.092704</td>\n",
       "      <td>1.86610</td>\n",
       "      <td>1.0571</td>\n",
       "      <td>0.57353</td>\n",
       "      <td>...</td>\n",
       "      <td>0.054015</td>\n",
       "      <td>0.14207</td>\n",
       "      <td>0.94598</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.5746</td>\n",
       "      <td>3.6147</td>\n",
       "      <td>86.435</td>\n",
       "      <td>4.2228</td>\n",
       "      <td>5.5497</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.61323</td>\n",
       "      <td>0.22960</td>\n",
       "      <td>1.4063</td>\n",
       "      <td>-7.3128</td>\n",
       "      <td>0.18732</td>\n",
       "      <td>0.187320</td>\n",
       "      <td>0.63070</td>\n",
       "      <td>1.1559</td>\n",
       "      <td>0.38677</td>\n",
       "      <td>...</td>\n",
       "      <td>0.134850</td>\n",
       "      <td>0.48431</td>\n",
       "      <td>0.86515</td>\n",
       "      <td>0.124440</td>\n",
       "      <td>6.3985</td>\n",
       "      <td>4.3158</td>\n",
       "      <td>127.210</td>\n",
       "      <td>2.8692</td>\n",
       "      <td>7.8980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         X1       X2       X3      X4       X5       X6        X7       X8  \\\n",
       "0  0.200550  0.37951  0.39641  2.0472  32.3510  0.38825  0.249760  1.33050   \n",
       "1  0.209120  0.49988  0.47225  1.9447  14.7860  0.00000  0.258340  0.99601   \n",
       "2  0.248660  0.69592  0.26713  1.5548  -1.1523  0.00000  0.309060  0.43695   \n",
       "3  0.081483  0.30734  0.45879  2.4928  51.9520  0.14988  0.092704  1.86610   \n",
       "4  0.187320  0.61323  0.22960  1.4063  -7.3128  0.18732  0.187320  0.63070   \n",
       "\n",
       "       X9      X10 ...        X56      X57      X58       X59     X60     X61  \\\n",
       "0  1.1389  0.50494 ...   0.121960  0.39718  0.87804  0.001924  8.4160  5.1372   \n",
       "1  1.6996  0.49788 ...   0.121300  0.42002  0.85300  0.000000  4.1486  3.2732   \n",
       "2  1.3090  0.30408 ...   0.241140  0.81774  0.76599  0.694840  4.9909  3.9510   \n",
       "3  1.0571  0.57353 ...   0.054015  0.14207  0.94598  0.000000  4.5746  3.6147   \n",
       "4  1.1559  0.38677 ...   0.134850  0.48431  0.86515  0.124440  6.3985  4.3158   \n",
       "\n",
       "       X62     X63      X64  X65  \n",
       "0   82.658  4.4158   7.4277    0  \n",
       "1  107.350  3.4000  60.9870    0  \n",
       "2  134.270  2.7185   5.2078    0  \n",
       "3   86.435  4.2228   5.5497    0  \n",
       "4  127.210  2.8692   7.8980    0  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_data1 = arff.loadarff('1year.arff')\n",
    "all_data1 = pd.DataFrame(raw_data1[0])\n",
    "\n",
    "raw_data2 = arff.loadarff('2year.arff')\n",
    "all_data2 = pd.DataFrame(raw_data2[0])\n",
    "\n",
    "raw_data3 = arff.loadarff('3year.arff')\n",
    "all_data3 = pd.DataFrame(raw_data3[0])\n",
    "\n",
    "raw_data4 = arff.loadarff('4year.arff')\n",
    "all_data4 = pd.DataFrame(raw_data4[0])\n",
    "\n",
    "raw_data5 = arff.loadarff('5year.arff')\n",
    "all_data5 = pd.DataFrame(raw_data5[0])\n",
    "\n",
    "\n",
    "\n",
    "x='X'\n",
    "col = [str(x)+str(i) for i in range(1,66)]\n",
    "all_data1.columns=col\n",
    "all_data2.columns=col\n",
    "all_data3.columns=col\n",
    "all_data4.columns=col\n",
    "all_data5.columns=col\n",
    "\n",
    "all_data1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imp_median = Imputer(missing_values = 'NaN', strategy='median')\n",
    "for i in range(1,65):\n",
    "    imp_median.fit(all_data1[['X'+str(i)]])\n",
    "    all_data1['X'+str(i)] = imp_median.transform(all_data1[['X'+str(i)]])\n",
    "    imp_median.fit(all_data2[['X'+str(i)]])\n",
    "    all_data2['X'+str(i)] = imp_median.transform(all_data2[['X'+str(i)]])\n",
    "    imp_median.fit(all_data3[['X'+str(i)]])\n",
    "    all_data3['X'+str(i)] = imp_median.transform(all_data3[['X'+str(i)]])\n",
    "    imp_median.fit(all_data4[['X'+str(i)]])\n",
    "    all_data4['X'+str(i)] = imp_median.transform(all_data4[['X'+str(i)]])\n",
    "    imp_median.fit(all_data5[['X'+str(i)]])\n",
    "    all_data5['X'+str(i)] = imp_median.transform(all_data5[['X'+str(i)]])\n",
    "\n",
    " \n",
    "\n",
    "\n",
    "X1 = all_data1.drop(['X65'], axis=1)\n",
    "y1 = all_data1['X65']\n",
    "\n",
    "X2 = all_data2.drop(['X65'], axis=1)\n",
    "y2 = all_data2['X65']\n",
    "\n",
    "X3 = all_data3.drop(['X65'], axis=1)\n",
    "y3 = all_data3['X65']\n",
    "\n",
    "X4 = all_data4.drop(['X65'], axis=1)\n",
    "y4 = all_data4['X65']\n",
    "\n",
    "X5 = all_data5.drop(['X65'], axis=1)\n",
    "y5 = all_data5['X65']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y1 = le.fit_transform(y1)\n",
    "y2 = le.fit_transform(y2)\n",
    "y3 = le.fit_transform(y3)\n",
    "y4 = le.fit_transform(y4)\n",
    "y5 = le.fit_transform(y5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train1, X_test1, y_train1, y_test1 = train_test_split(X1, y1, test_size=0.10, random_state=9)\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X2, y2, test_size=0.10, random_state=9)\n",
    "X_train3, X_test3, y_train3, y_test3 = train_test_split(X3, y3, test_size=0.10, random_state=9)\n",
    "X_train4, X_test4, y_train4, y_test4 = train_test_split(X4, y4, test_size=0.10, random_state=9)\n",
    "X_train5, X_test5, y_train5, y_test5 = train_test_split(X5, y5, test_size=0.10, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=10, max_features='log2', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=9, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1 = RandomForestClassifier(max_depth=10, random_state=9, max_features=\"log2\")\n",
    "clf_1.fit(X_train1,y_train1)\n",
    "\n",
    "clf_2 = RandomForestClassifier(max_depth=10, random_state=9, max_features=\"log2\")\n",
    "clf_2.fit(X_train2,y_train2)\n",
    "\n",
    "clf_3 = RandomForestClassifier(max_depth=10, random_state=9, max_features=\"log2\")\n",
    "clf_3.fit(X_train3,y_train3)\n",
    "\n",
    "clf_4 = RandomForestClassifier(max_depth=10, random_state=9, max_features=\"log2\")\n",
    "clf_4.fit(X_train4,y_train4)\n",
    "\n",
    "clf_5 = RandomForestClassifier(max_depth=10, random_state=9, max_features=\"log2\")\n",
    "clf_5.fit(X_train5,y_train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction1 = clf_1.predict(X_test1)\n",
    "prediction2 = clf_2.predict(X_test2)\n",
    "prediction3 = clf_3.predict(X_test3)\n",
    "prediction4 = clf_4.predict(X_test4)\n",
    "prediction5 = clf_5.predict(X_test5)\n",
    "\n",
    "#print roc_auc_score(y_test1, prediction1)\n",
    "#print roc_auc_score(y_test2, prediction2)\n",
    "#print roc_auc_score(y_test3, prediction3)\n",
    "#print roc_auc_score(y_test4, prediction4)\n",
    "#print roc_auc_score(y_test5, prediction5)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#print classification_report(y_test1, prediction1)\n",
    "#print classification_report(y_test2, prediction2)\n",
    "#print classification_report(y_test3, prediction3)\n",
    "#print classification_report(y_test4, prediction4)\n",
    "#print classification_report(y_test5, prediction5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels1 = X_train1.columns\n",
    "lst1=[]\n",
    "for feature in zip(labels1, clf_1.feature_importances_):\n",
    "    lst1.append(list(feature))\n",
    "#print lst1\n",
    "\n",
    "labels2 = X_train2.columns\n",
    "lst2=[]\n",
    "for feature in zip(labels2, clf_2.feature_importances_):\n",
    "    lst2.append(list(feature))\n",
    "\n",
    "#print lst2\n",
    "\n",
    "labels3 = X_train3.columns\n",
    "lst3=[]\n",
    "for feature in zip(labels3, clf_3.feature_importances_):\n",
    "    lst3.append(list(feature))\n",
    "\n",
    "#print lst3\n",
    "\n",
    "labels4 = X_train4.columns\n",
    "lst4=[]\n",
    "for feature in zip(labels3, clf_4.feature_importances_):\n",
    "    lst4.append(list(feature))\n",
    "\n",
    "#print lst4\n",
    "\n",
    "labels5 = X_train5.columns\n",
    "lst5=[]\n",
    "for feature in zip(labels5, clf_5.feature_importances_):\n",
    "    lst5.append(list(feature))\n",
    "\n",
    "#print lst5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst1 = pd.DataFrame(lst1)\n",
    "lst2 = pd.DataFrame(lst2)\n",
    "lst3 = pd.DataFrame(lst3)\n",
    "lst4 = pd.DataFrame(lst4)\n",
    "lst5 = pd.DataFrame(lst5)\n",
    "\n",
    "lst1.to_csv('D:\\MyData\\GreyAtom\\Hackathon\\lst1.csv')\n",
    "lst2.to_csv('D:\\MyData\\GreyAtom\\Hackathon\\lst2.csv')\n",
    "lst3.to_csv('D:\\MyData\\GreyAtom\\Hackathon\\lst3.csv')\n",
    "lst4.to_csv('D:\\MyData\\GreyAtom\\Hackathon\\lst4.csv')\n",
    "lst5.to_csv('D:\\MyData\\GreyAtom\\Hackathon\\lst5.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
